{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPI Mock data creation and SQL Logic v4 #6 (6.1, 6.2, 6.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       file_id   post_out_id            timestamp\n",
      "0  FID00000001  POID00000001  2024-03-14 18:57:54\n",
      "1  FID00000002  POID00000002  2024-02-17 21:22:33\n",
      "2  FID00000003  POID00000003  2024-03-23 11:27:06\n",
      "3  FID00000004  POID00000004  2024-01-19 14:52:21\n",
      "4  FID00000005  POID00000005  2024-02-06 14:28:16\n",
      "Data saved to 'sps_post_out_requests.parquet'.\n",
      "file_id        object\n",
      "post_out_id    object\n",
      "timestamp      object\n",
      "dtype: object\n",
      "------------------------\n",
      "       file_id  post_out_type file_received_timestamp\n",
      "0  FID00000001  Prize Warrant     2024-03-12 18:57:54\n",
      "1  FID00000002    daily_files     2024-02-12 21:22:33\n",
      "2  FID00000003  Prize Warrant     2024-03-22 11:27:06\n",
      "3  FID00000004  Prize Warrant     2024-01-07 14:52:21\n",
      "4  FID00000005  Prize Warrant     2024-02-03 14:28:16\n",
      "Data saved to 'ppa_post_out_bulk_requests.parquet'.\n",
      "file_id                    object\n",
      "post_out_type              object\n",
      "file_received_timestamp    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Mock data for Batch #7 - Post Out Requests\n",
    "\n",
    "# Required fields:\n",
    "#   file_id\n",
    "#   post_out_id\n",
    "#   timestamp\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "### Create Batch 7\n",
    "# Set conditions\n",
    "np.random.seed(0)\n",
    "batch7_output_filename = 'sps_post_out_requests.parquet'\n",
    "num_samples = 1000\n",
    "\n",
    "file_ids = ['FID' + f'{i:08}' for i in range(1, num_samples + 1)]\n",
    "post_out_ids = ['POID' + f'{i:08}' for i in range(1, num_samples + 1)]\n",
    "\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "end_date = pd.to_datetime(datetime.now()) \n",
    "timestamps = pd.to_datetime(np.random.randint(start_date.value, end_date.value, num_samples), unit='ns')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'file_id': file_ids,\n",
    "    'post_out_id': post_out_ids,\n",
    "    'timestamp': timestamps\n",
    "})\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')).dt.round('s')\n",
    "df['timestamp'] = df['timestamp'].astype(str)\n",
    "df.to_parquet(batch7_output_filename, index=False)\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Data saved to '{batch7_output_filename}'.\")\n",
    "print(df.dtypes)\n",
    "print('------------------------')\n",
    "\n",
    "\n",
    "\n",
    "### Create Batch 24\n",
    "# Set conditions\n",
    "batch24_output_filename = 'ppa_post_out_bulk_requests.parquet'\n",
    "post_out_types_list = ['Prize Warrant', 'daily_files', 'Scheduled Statements']\n",
    "\n",
    "length_min_days = 1\n",
    "length_max_days = 14\n",
    "\n",
    "\n",
    "df['post_out_type'] = np.random.choice(post_out_types_list, size=len(df))\n",
    "\n",
    "random_days = pd.to_timedelta(np.random.randint(length_min_days, length_max_days, size=len(df)), unit='D')\n",
    "df['file_received_timestamp'] = pd.to_datetime(df['timestamp']) - random_days\n",
    "df['file_received_timestamp'] = pd.to_datetime(df['file_received_timestamp']).astype(str)\n",
    "\n",
    "df = df.drop(columns=['timestamp','post_out_id'])\n",
    "\n",
    "df.to_parquet(batch24_output_filename, index=False)\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Data saved to '{batch24_output_filename}'.\")\n",
    "print(df.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Logic for KPI 6.1\n",
    "for today-30 to today \\\n",
    "s1. b24 where post_out_type = 'Prize Warrant' \\\n",
    "s2. join b24 b7 on file_id \\\n",
    "s3. time_to_send = b7.timestamp - b24.file_recieved_timestamp \\\n",
    "s4. count s2 \\\n",
    "s5.count s3 where time_to_send <= 7 days \\\n",
    "s6. s5/s4*100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PC_LTE_7_days\n",
      "0      63.380282\n"
     ]
    }
   ],
   "source": [
    "import pandasql as ps\n",
    "import pandas as pd\n",
    "\n",
    "batch7_df = pd.read_parquet(batch7_output_filename)\n",
    "batch24_df = pd.read_parquet(batch24_output_filename)\n",
    "\n",
    "sql_query = \"\"\"\n",
    "WITH selected_df AS (\n",
    "    SELECT *\n",
    "    ,julianday(timestamp) - julianday(file_received_timestamp) AS time_to_send\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM batch24_df\n",
    "        WHERE post_out_type = 'Prize Warrant'\n",
    "        AND (file_received_timestamp BETWEEN DATETIME('NOW','-30 days') AND DATETIME('NOW'))\n",
    "    ) b24\n",
    "    LEFT JOIN batch7_df b7\n",
    "    ON b24.file_id = b7.file_id\n",
    ")\n",
    ",\n",
    "agg_results AS (\n",
    "SELECT COUNT(*) AS Total\n",
    ",SUM(CASE WHEN time_to_send <= 7 THEN 1 ELSE 0 END) AS Time_to_send_less_than_7_days\n",
    "FROM selected_df\n",
    ")\n",
    "\n",
    "SELECT (Time_to_send_less_than_7_days * 1.0 / Total) * 100 AS PC_LTE_7_days\n",
    "FROM agg_results\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(sql_query,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL logic used in ETL_KPI_data_KPI6.2 in AWS Glue\n",
    "# Note, some functions have been changed to accomdate the change from SQLite to Postgres\n",
    "\n",
    "\n",
    "WITH current_date_id AS (\n",
    "    SELECT myDimDate.pk_id\n",
    "    FROM myDimDate\n",
    "    WHERE myDimDate.date = CURRENT_DATE\n",
    ")\n",
    ",\n",
    "current_kpi_id AS (\n",
    "    SELECT pk_id\n",
    "    FROM myDimKPI\n",
    "    WHERE kpi_reference = '6.1'\n",
    ")\n",
    ",\n",
    "selected_df AS (\n",
    "    SELECT *\n",
    "    ,EXTRACT(DAY FROM (timestamp - file_received_timestamp)) AS days_to_process\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM df\n",
    "        WHERE post_out_type = 'Prize Warrant'\n",
    "        AND (file_received_timestamp BETWEEN (CURRENT_DATE-31) AND (CURRENT_DATE-1))\n",
    "    )\n",
    ")\n",
    ",\n",
    "agg_results AS (\n",
    "SELECT COUNT(*) AS Total\n",
    ",SUM(CASE WHEN days_to_process <= 7 THEN 1 ELSE 0 END) AS time_to_process_lte_7_days\n",
    "FROM selected_df\n",
    ")\n",
    "\n",
    "SELECT (SELECT pk_id FROM current_date_id) AS fk_date_id\n",
    ",(SELECT pk_id FROM current_kpi_id) AS fk_kpi_id\n",
    ",(time_to_process_lte_7_days * 100.0 / Total) AS Value\n",
    "FROM agg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Logic for KPI 6.2\n",
    "\n",
    "for today - 30 to today \\\n",
    "for post_out_type = 'daily_files' \\\n",
    "s1. B24.Day =  reset a day to today - 13hrs for start and today @ 13hrs for end and select date for today \\\n",
    "s2. B7.Processed_Day = extract the date the file is posted to SFTP \\\n",
    "s3. join s1 & s2 based on File_id where Day = Processed_Day then Success = 1 else 0 \\\n",
    "s4. count s3 where Success = 1/count s3*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PC_Processed_Same_Day\n",
      "0              10.447761\n"
     ]
    }
   ],
   "source": [
    "import pandasql as ps\n",
    "import pandas as pd\n",
    "\n",
    "batch7_df = pd.read_parquet(batch7_output_filename)\n",
    "batch24_df = pd.read_parquet(batch24_output_filename)\n",
    "\n",
    "# WIP\n",
    "sql_query = \"\"\"\n",
    "WITH selected_df AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM batch24_df\n",
    "        WHERE post_out_type = 'daily_files'\n",
    "        AND (file_received_timestamp BETWEEN DATETIME('NOW','-30 days') AND DATETIME('NOW'))\n",
    "    ) b24\n",
    "    LEFT JOIN batch7_df b7\n",
    "    ON b24.file_id = b7.file_id\n",
    ")\n",
    ",\n",
    "adjusted_dates_df AS (\n",
    "SELECT *\n",
    ",CASE\n",
    "    WHEN strftime('%H', file_received_timestamp) < '13' THEN DATE(file_received_timestamp)\n",
    "    ELSE DATE(file_received_timestamp, '+1 day')\n",
    "END AS recv_adjusted_date\n",
    ",DATE(timestamp) AS processed_adjusted_date\n",
    "FROM selected_df\n",
    ")\n",
    ",\n",
    "agg_results AS (\n",
    "SELECT *\n",
    ",CASE\n",
    "    WHEN DATE(recv_adjusted_date) = DATE(processed_adjusted_date) THEN 1\n",
    "    ELSE 0\n",
    "END AS processed_same_day\n",
    "FROM adjusted_dates_df\n",
    ")\n",
    "\n",
    "SELECT (SUM(processed_same_day) * 1.0 / COUNT(*)) * 100 AS PC_Processed_Same_Day\n",
    "FROM agg_results\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(sql_query,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL logic used in ETL_KPI_data_KPI6.2 in AWS Glue\n",
    "# Note, some functions have been changed to accomdate the change from SQLite to Postgres\n",
    "\n",
    "WITH current_date_id AS (\n",
    "    SELECT myDimDate.pk_id\n",
    "    FROM myDimDate\n",
    "    WHERE myDimDate.date = CURRENT_DATE\n",
    ")\n",
    ",\n",
    "current_kpi_id AS (\n",
    "    SELECT pk_id\n",
    "    FROM myDimKPI\n",
    "    WHERE kpi_reference = '6.2'\n",
    ")\n",
    ",\n",
    "selected_df AS (\n",
    "    SELECT *\n",
    "    ,EXTRACT(DAY FROM (timestamp - file_received_timestamp)) AS days_to_process\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM df\n",
    "        WHERE post_out_type = 'daily_files'\n",
    "        AND (file_received_timestamp BETWEEN (CURRENT_DATE-31) AND (CURRENT_DATE-1))\n",
    "    )\n",
    ")\n",
    ",\n",
    "adjusted_dates_df AS (\n",
    "    SELECT *\n",
    "    ,CASE\n",
    "        WHEN EXTRACT(HOUR FROM file_received_timestamp) < 13 THEN DATE(file_received_timestamp)\n",
    "        ELSE\n",
    "            CASE\n",
    "                WHEN EXTRACT(DOW FROM file_received_timestamp) = 5 THEN DATE(file_received_timestamp) + 3 -- For Friday, +3 days\n",
    "                WHEN EXTRACT(DOW FROM file_received_timestamp) = 6 THEN DATE(file_received_timestamp) + 2 -- For Saturday, +2 days\n",
    "                ELSE DATE(file_received_timestamp) + 1 -- For Sunday to Thursday, +1 day\n",
    "            END\n",
    "    END AS recv_adjusted_date\n",
    "    ,DATE(timestamp) AS processed_adjusted_date\n",
    "    FROM selected_df\n",
    ")\n",
    ",\n",
    "agg_results AS (\n",
    "    SELECT *\n",
    "    ,CASE\n",
    "        WHEN DATE(recv_adjusted_date) = DATE(processed_adjusted_date) THEN 1\n",
    "        ELSE 0\n",
    "    END AS processed_same_day\n",
    "    FROM adjusted_dates_df\n",
    ")\n",
    "\n",
    "SELECT (SELECT pk_id FROM current_date_id) AS fk_date_id\n",
    ",(SELECT pk_id FROM current_kpi_id) AS fk_kpi_id\n",
    ",(SUM(processed_same_day) * 100.0 / COUNT(*)) AS Value\n",
    "FROM agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "Change the +1day into working days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Logic for KPI 6.3\n",
    "\n",
    "for today-30 to today \\\n",
    "s1. b24 where post_out_type = 'Scheduled Statements' \\\n",
    "s2. join b24 b7 on file_id \\\n",
    "s3. time_to_send = b7.timestamp - b24.file_recieved_timestamp \\\n",
    "s4. count s2 \\\n",
    "s5.count s3 where time_to_send <= 7 days \\\n",
    "s6. s5/s4*100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PC_LTE_7_days\n",
      "0      54.054054\n"
     ]
    }
   ],
   "source": [
    "import pandasql as ps\n",
    "import pandas as pd\n",
    "\n",
    "batch7_df = pd.read_parquet(batch7_output_filename)\n",
    "batch24_df = pd.read_parquet(batch24_output_filename)\n",
    "\n",
    "sql_query = \"\"\"\n",
    "WITH selected_df AS (\n",
    "    SELECT *\n",
    "    ,julianday(timestamp) - julianday(file_received_timestamp) AS time_to_send\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM batch24_df\n",
    "        WHERE post_out_type = 'Scheduled Statements'\n",
    "        AND (file_received_timestamp BETWEEN DATETIME('NOW','-30 days') AND DATETIME('NOW'))\n",
    "    ) b24\n",
    "    LEFT JOIN batch7_df b7\n",
    "    ON b24.file_id = b7.file_id\n",
    ")\n",
    ",\n",
    "agg_results AS (\n",
    "SELECT COUNT(*) AS Total\n",
    ",SUM(CASE WHEN time_to_send <= 7 THEN 1 ELSE 0 END) AS Time_to_send_less_than_7_days\n",
    "FROM selected_df\n",
    ")\n",
    "\n",
    "SELECT (Time_to_send_less_than_7_days * 1.0 / Total) * 100 AS PC_LTE_7_days\n",
    "FROM agg_results\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ps.sqldf(sql_query,locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL logic used in ETL_KPI_data_KPI6.3 in AWS Glue\n",
    "# Note, some functions have been changed to accomdate the change from SQLite to Postgres\n",
    "\n",
    "\n",
    "WITH current_date_id AS (\n",
    "    SELECT myDimDate.pk_id\n",
    "    FROM myDimDate\n",
    "    WHERE myDimDate.date = CURRENT_DATE\n",
    ")\n",
    ",\n",
    "current_kpi_id AS (\n",
    "    SELECT pk_id\n",
    "    FROM myDimKPI\n",
    "    WHERE kpi_reference = '6.3'\n",
    ")\n",
    ",\n",
    "selected_df AS (\n",
    "    SELECT *\n",
    "    ,EXTRACT(DAY FROM (timestamp - file_received_timestamp)) AS days_to_process\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM df\n",
    "        WHERE post_out_type = 'Scheduled Statements'\n",
    "        AND (file_received_timestamp BETWEEN (CURRENT_DATE-31) AND (CURRENT_DATE-1))\n",
    "    )\n",
    ")\n",
    ",\n",
    "agg_results AS (\n",
    "SELECT COUNT(*) AS Total\n",
    ",SUM(CASE WHEN days_to_process <= 7 THEN 1 ELSE 0 END) AS time_to_process_lte_7_days\n",
    "FROM selected_df\n",
    ")\n",
    "\n",
    "SELECT (SELECT pk_id FROM current_date_id) AS fk_date_id\n",
    ",(SELECT pk_id FROM current_kpi_id) AS fk_kpi_id\n",
    ",(time_to_process_lte_7_days * 100.0 / Total) AS Value\n",
    "FROM agg_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
